需要一个简短的这个功能的配置指南。用于告诉大家怎么配
### 配置指南（OpenAI 兼容转发 API）

- 模块位置
  - 路由：`/v1/chat/completions`（别名：`/api/v1/chat/completions`）
  - 工具类（后端内部可用）：`src/framework/utils/llm-client.ts`

- 必备环境变量
  - `OPENAI_API_KEY`: 上游 OpenAI（或兼容服务）的 Key
  - 可选 `OPENAI_BASE_URL`: 默认 `https://api.openai.com`，换第三方时设置，如：
    - `https://api.bltcy.ai`
    - `https://openkey.cloud`
    - 其他 OpenAI 兼容服务地址
  - 部署到 Vercel：在 Project Settings → Environment Variables 设置以上变量

- 本地启动
  - 在项目根目录新建 `.env`：
    - `OPENAI_API_KEY=xxxx`
    - 可选 `OPENAI_BASE_URL=https://api.bltcy.ai`
  - 启动：`npm run dev`
  - 健康检查：`GET /health`

- Vercel（已内置配置）
  - `vercel.json` 已设置函数超时 `maxDuration: 60`
  - 路由重写到 `api/index.ts`，Fastify 自动接管一切请求
  - 只需在 Vercel 环境变量里配置 `OPENAI_API_KEY`（和可选 `OPENAI_BASE_URL`），即可使用

- 前端/客户端调用方式
  - 非流式（示例 curl）：
    ```
    curl -X POST https://your-host/v1/chat/completions \
      -H "Content-Type: application/json" \
      -d '{
        "model": "gpt-3.5-turbo",
        "messages": [{"role":"user","content":"hello"}],
        "stream": false
      }'
    ```
  - 流式（SSE，示例 curl）：
    ```
    curl -N -X POST https://your-host/v1/chat/completions \
      -H "Content-Type: application/json" \
      -d '{
        "model": "gpt-3.5-turbo",
        "messages": [{"role":"user","content":"hello"}],
        "stream": true
      }'
    ```
  - 用 OpenAI SDK（将 baseURL 指向你的后端，Key 任意或留空也可，后端会使用服务器端 `OPENAI_API_KEY`）：
    ```ts
    import OpenAI from "openai";
    const client = new OpenAI({
      baseURL: "https://your-host", // 或 https://your-host/api
      apiKey: "unused-on-server",   // 服务端会用自己的 OPENAI_API_KEY
    });
    const res = await client.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [{ role: "user", content: "hello" }],
      stream: false,
    });
    ```

- 注意事项
  - 该接口默认不校验前端传入的 Authorization；建议结合你现有鉴权或 CORS 策略限制来源。
  - 需要切换上游厂商时，仅需改 `OPENAI_BASE_URL`，前端代码无需改动。